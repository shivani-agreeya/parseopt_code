spark.CURRENT_ENVIRONMENT DEV
spark.POSTGRES_CONN_URL jdbc:postgresql://localhost:5432/postgres?currentSchema=dmat_qa&user=postgres&password=postgres-d
spark.POSTGRES_CONN_SDE_URL jdbc:postgresql://localhost:5432/postgres?currentSchema=sde&user=postgres&password=postgres-d&socketTimeout=5
spark.POSTGRES_DRIVER org.postgresql.Driver
spark.POSTGRES_DB_URL jdbc:postgresql://localhost:5432/postgres?currentSchema=dmat_qa
spark.POSTGRES_DB_USER postgres
spark.POSTGRES_DB_PWD postgres-d
spark.HIVE_HDFS_PATH hdfs://namenode:9000/apps/hive/warehouse/dmat_logs.db/
spark.HDFS_FILE_DIR_PATH hdfs://namenode:9000/oneparser/data/dmat/staging/
spark.HDFS_URI hdfs://namenode:9000
spark.DM_USER_DUMMY 10088
spark.HIVE_DB dmat_logs.
spark.FINAL_HIVE_TBL_NAME FinalLogRecord_DMAT
spark.HIVE_MIN_PARTITION 16
spark.LOG_GENERAL_EXCEPTION FALSE
spark.LOG_LEVEL WARN
spark.ZOOKEEPER_HOSTS localhost:2181
spark.BOOTSTRAP_SERVERS localhost:9092
spark.MAX_OFFSETS_PER_TRIGGER 1
spark.STARTING_OFFSETS earliest
spark.KAFKA_GROUP_ID DMAT
spark.INGESTION_KAFKA_TOPIC logs
spark.NOTIFICATION_KAFKA_TOPIC ns
spark.PROCESS_PARAM_VALUES_KAFKA_TOPIC process
spark.HIVE_KAFKA_TOPIC hiveprocessor
spark.ES_KAFKA_TOPIC elastic
spark.SCHEMA_REGISTRY_URL http://localhost:8081

spark.PARAM_VALUE_SCHEMA_REGISTRY_ID latest
spark.CHECKPOINT_LOCATION file:////checkpoints
spark.WRITE_SEQ_TO_HDFS_CHECKPOINT_SEGMENT write_seq_to_hdfs
spark.READ_SEQ_TO_HIVE_CHECKPOINT_SEGMENT read_seq_to_hive
spark.PROCESS_DMAT_RECORDS_CHECKPOINT_SEGMENT process_dmat_records

spark.network.timeout 6000s
spark.executor.heartbeatInterval 600s
spark.storage.blockManagerSlaveTimeoutMs 6000s

spark.sql.adaptive.enabled true
spark.sql.hive.metastore.jars maven

spark.serializer org.apache.spark.serializer.KryoSerializer
spark.kryo.classesToRegister org.apache.spark.sql.execution.joins.UnsafeHashedRelation,org.apache.spark.sql.execution.datasources.WriteTaskResult,org.apache.spark.internal.io.FileCommitProtocol$TaskCommitMessage,org.apache.spark.sql.execution.datasources.ExecutedWriteSummary,org.apache.spark.sql.execution.datasources.BasicWriteTaskStats,[Lorg.apache.spark.sql.catalyst.InternalRow;,scala.reflect.ClassTag$$anon$1,org.apache.spark.sql.execution.columnar.CachedBatch,org.apache.spark.sql.catalyst.InternalRow,[[B,org.apache.spark.sql.catalyst.expressions.GenericInternalRow,org.apache.spark.unsafe.types.UTF8String
spark.kryo.registrationRequired true

spark.sql.shuffle.partitions 16
spark.files.ignoreCorruptFiles true
spark.files.ignoreMissingFiles true

spark.hadoop.hive.metastore.uris thrift://localhost:9083

spark.CACHE_FINAl_DATA2HIVE_DATAFRAME false

spark.PATH_TO_CORE_SITE file:////HadoopConf/core-site.xml
spark.PATH_TO_HDFS_SITE file:////HadoopConf/hdfs-site.xml