spring.profiles.active=dev,zk-store,gw-stub
current_environment=dev

spring.datasource.url=jdbc:postgresql://localhost:5432/postgres
spring.datasource.username=postgres
spring.datasource.password=pw
spring.datasource.driver-class-name=org.postgresql.Driver

spring.jpa.show-sql=true
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQL94Dialect
spring.jpa.properties.hibernate.default_schema=dmat_qa

spring.batch.initialize-schema=always

spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.LongSerializer
spring.kafka.producer.value-serializer=io.confluent.kafka.serializers.KafkaAvroSerializer
spring.kafka.producer.bootstrap-servers=0.0.0.0:9092
spring.kafka.producer.properties.schema.registry.url=http://0.0.0.0:8081
#spring.kafka.template.default-topic=logs

spring.batch.job.enabled=false

metadata-store.zookeeper-root=/zookeeper-metadatastore
metadata-store.properties-persisting-dir=/tmp/spring-integration
#metadata-store.metastore_prefix=dmat

zookeeper.connectString=0.0.0.0:2181
zookeeper.baseSleepTimeMs=1000
zookeeper.maxSleepMs=3
zookeeper.maxRetries=10
zookeeper.blockUntilConnectedWait=10
zookeeper.blockUntilConnectedUnit=SECONDS

#enables GW API
#data.job.gw_api_url=http://localhost:8080/dbgw/api/v1/logs?size=3

data.job.job_name=logsJob
data.job.step_name=logsStep

data.job.dm_user_dummy=10088
data.job.dm_user_drm=10091
data.job.dm_user_dml=10069
data.job.dm_user_sig=10092

batch.commit-interval=5

data.job.process_server_upload=false
data.job.process_rm_only=false

#Ftp Dir Details
data.job.src_server_upload_dir=/ftpdata/month0/ServerUpload/
data.job.src_ftp_dir=/ftpdata/month0/StaggingData/
data.job.src_ftp_dir_drm_dml=/ftpdata/month0/StaggingData/RootMetric/
data.job.ftp_output_path=/ftpdata/month0/oneparser/staging/
data.job.ftp_processed_path=/ftpdata/month0/oneparser/processed/
data.job.ftp_root_metric_processed_path=/ftpdata/month0/oneparser/processed_dml/
data.job.ftp_failed_path=/ftpdata/month0/oneparser/failed/
data.job.db_save_path=/oneparser/processed/
data.job.db_fail_path=/oneparser/failed/

#HDFS Dir Details
data.job.hdfs_uri=hdfs://0.0.0.0:9000
data.job.hdfs_output_path=/oneparser/data/dmat/staging/

data.job.fixedRate=60000

# Actuator / Management
management.endpoints.web.exposure.include=health,info,env,logfile,loggers,metrics
management.endpoint.health.show-details=always

logging.level.root=info
logging.file.name=../logs/oneparser-datacopier.log
