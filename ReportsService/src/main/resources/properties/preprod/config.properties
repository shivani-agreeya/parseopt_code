spark.hdfs.sequence.input = hdfs://10.20.40.180:8020/oneparser/data/dlf/
spark.hdfs.sequence.output = /oneparser/data/dmat/staging/
spark.hdfs.ftp.output = hdfs://10.20.40.180:8020/oneparser/data/dlf/
spark.hdfs.default.fs = hdfs://10.20.40.180:8020

hbase.zookeeper.quorum=oneparserdatapp01.vzwdt.local,oneparsernamenodepp.vzwdt.local,oneparsernamenodepp02.vzwdt.local
hbase.rootdir = file:///usr/hdp/2.6.5.0-292/hbase
zookeeper.znode.parent = /hbase-unsecure
spark.hdfs.hbase.sequence.input = hdfs://10.20.40.180:8020/oneparser/data/sequence/logviewer/

jdbc.driverClassName = org.postgresql.Driver
jdbc.url = jdbc:postgresql://10.20.40.109:5432/dmat_preprod?currentSchema=dmat
jdbc.username = postgres
jdbc.password = postgres123

prepost.report.url=https://vzwdt.com/DMATPreProd/DMATBDPPApp/prepostrpt/v1/uploadprepostrpt?jobid=
server.context-path=/PPR
server.port=8082
spark.seqLimit = 10
spark.hiveLimit = 10
spark.esLimit = 10
spark.seqSleepTime = 15000
spark.hiveSleepTime = 15000
spark.esSleepTime = 15000
spark.timeInterval = 120
spark.seqTimeInterval = 120
spark.hiveTimeInterval = 120
spark.esTimeInterval = 120
spark.repartition = 1400
spark.CURRENT_ENVIRONMENT = PREPROD
spark.POSTGRES_CONN_URL = jdbc:postgresql://10.20.40.109:5432/dmat_preprod?currentSchema=dmat&user=postgres&password=postgres123
spark.POSTGRES_CONN_SDE_URL = jdbc:postgresql://10.20.40.109:5432/dmat_preprod?currentSchema=sde&user=postgres&password=postgres123&socketTimeout=5
spark.POSTGRES_DRIVER = org.postgresql.Driver
spark.POSTGRES_DB_URL = jdbc:postgresql://10.20.40.109:5432/dmat_preprod?currentSchema=dmat
spark.POSTGRES_DB_SDE_URL = jdbc:postgresql://10.20.40.109:5432/dmat_preprod?currentSchema=sde
spark.POSTGRES_DB_USER = postgres
spark.POSTGRES_DB_PWD = postgres123
spark.HIVE_HDFS_PATH = hdfs://10.20.40.180:8020/apps/hive/warehouse/dmat_logs.db/
spark.HIVE_DB = dmat_logs.
spark.HDFS_FILE_DIR_PATH = hdfs://10.20.40.180:8020/oneparser/data/dmat/staging/
spark.HDFS_URI = hdfs://10.20.40.180:8020
spark.ES_HOST_PATH = 10.20.40.28
spark.ES_PORT_NUM = 9202
spark.DM_USER_DUMMY=10016
spark.MaxRTP_PacketLossVal = 10000
spark.REPORT_LOG_CUTOFF_DATE =2019-09-30

spark.ZOOKEEPER_HOSTS = 127.0.0.1:2181
spark.BOOTSTRAP_SERVERS = 127.0.0.1:9092
spark.MAX_OFFSETS_PER_TRIGGER = 5
spark.STARTING_OFFSETS = earliest
spark.KAFKA_GROUP_ID = DMAT
spark.INGESTION_KAFKA_TOPIC = logs
spark.NOTIFICATION_KAFKA_TOPIC = logsnotification
spark.PROCESS_PARAM_VALUES_KAFKA_TOPIC = processparamvalues
spark.HIVE_KAFKA_TOPIC = logshive
spark.ES_KAFKA_TOPIC = logses
spark.SCHEMA_REGISTRY_URL = http://127.0.0.1:8081
spark.PARAM_VALUE_SCHEMA_REGISTRY_ID = latest
spark.CHECKPOINT_LOCATION = checkpoints